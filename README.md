# Emotion-Recognition
Классификация эмоций на аудио, используя эмбеддинги предобученной модели

Wav2Vec2 - модель для распознования речи на аудио. Мы решаем немного другую задачу, но предобученная модель всё равно может нам в этом помочь.

Так как Wav2Vec2 обучилась на большом количестве аудио, в её скрытых слоях накопилась важная обощающая информация, которую можно использоваь как фичи для решения соверешенно других задач. То есть мы можем взять новые аудио, получить их эмбеддинги и на них решать задачу классфикации. Перед этим нужно только поменять частоту дискретизации на 16k и отнормализовать данные, т.к. в документации напрямую сказано, что часто это существенно улучшает качество моделей

Для решения задачи я сравнил несколько классификаторов, реализованных в sklearn. Наиболее эффективным оказался градиентный бустинг с accuracy 48%, что не является плохим результатом,  т.к. меток классов 8, то есть "подбрасывание монетки" дало бы нам только 12.5%. В других работах на аналогичных данных достигается accuracy в 60% https://www.kaggle.com/code/shivamburnwal/speech-emotion-recognition

Датасет RAVDESS состоит из аудио, озвученных 24 разными актёрами, в равной пропорции женщинами и мужчинами. Каждый актёр озвучил каждую фразу каждой эмоцией по два раза, правда разных фраз всего было две - "Kids are talking by the door" и "Dogs are sitting by the door". Помимо прочего, в датасете есть сила эмоции normal и strong, но для neutral эмоции strong нет. Из-за этого класс neutral несбалансирован, так что при разделениях датасета использовалась стратификация - чтобы в валидационную и тренировочную части попадали объекты равномерно из каждого класса.

Можно было бы обучить многослойную сеть и подобрать гиперпараметры - у неё потенциально может быть существенное улучшение скора. Дополнительно можно увеличить наш датасет путём аугментаций. Дело в том, что 1.5к объектов - это не так и много, когда дело доходит до обучения сложных моделей. При этом метка класса не должна меняться от добавления шумов, небольшого изменения громкости или высоты звука, в то время, когда это существенно изменит эмбеддинг в Wav2Vec. Таким образом, мы получим новые данные.

![img.png](img.png)