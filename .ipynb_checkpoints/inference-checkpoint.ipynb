{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac0912e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from transformers import Wav2Vec2FeatureExtractor, Wav2Vec2Model\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "debdfac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-large-xlsr-53 and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Initialising\n",
    "\n",
    "# we use the facebook pretrained model\n",
    "model_name = \"facebook/wav2vec2-large-xlsr-53\"\n",
    "feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(model_name)\n",
    "model = Wav2Vec2Model.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bf4d250",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature(input_audio):\n",
    "    \n",
    "    # normilising the input, so that it has zero mean and unit variance\n",
    "    normalised_input = feature_extractor(input_audio, return_tensors=\"pt\", \n",
    "                                         feature_size=1, sampling_rate=sample_rate,\n",
    "                                        padding=True)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # getting the representation in Wav2Vec2\n",
    "        outputs = model(normalised_input.input_values, output_hidden_states=True)\n",
    "\n",
    "    embeddings = outputs.last_hidden_state\n",
    "\n",
    "    return np.mean(embeddings[0].numpy(), axis=0).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0330e9be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1550/1550 [11:47<00:00,  2.19it/s]\n"
     ]
    }
   ],
   "source": [
    "test_folder = \"data/test_dataset/\"\n",
    "test_directory_list = os.listdir(test_folder)\n",
    "\n",
    "files_path = []\n",
    "features = []\n",
    "\n",
    "for file_path in tqdm(test_directory_list):\n",
    "    input_audio, sample_rate = librosa.load(test_folder+file_path,  sr=16000)\n",
    "    features.append(get_feature(input_audio))\n",
    "\n",
    "features = np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d821e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# save the model to disk\n",
    "filename = 'data/GradientBoostingClassifier_weights.sav'\n",
    "\n",
    "# load the model from disk\n",
    "clf = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62fe61d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = clf.predict_proba(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d7b83f0",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only length-1 arrays can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43my_predicted\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: only length-1 arrays can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "float(y_predicted[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "35c685f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = ''\n",
    "\n",
    "for i in range(len(y_predicted)):\n",
    "    output += test_directory_list[i] + '|' + '|'.join(\n",
    "        str(val) for val in y_predicted[i]) + \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c9321d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"answers.txt\", \"w\") as f:\n",
    "    f.write(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f395bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
